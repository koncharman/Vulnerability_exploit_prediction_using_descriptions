###For GloVe
tcm=readRDS("tcm_train")
dimensions=200

library(text2vec)
lr=0.05 ; ct=-1
glove = GlobalVectors$new(rank = dimensions, x_max = 1000) # ,learning_rate=lr
wv_main = glove$fit_transform(as.matrix(tcm_glove), convergence_tol = ct, n_threads = 8) #, n_iter = 100

#
wv_context = glove$components
dim(wv_context)

#
glove_vectors = wv_main + t(wv_context) 



##Fit fuzzy k-means model

glove_vectors=readRDS("te_tcm/glove_word_vectors_2015_2021_cve_te_tcm")
#glove_vectors=readRDS("tSparse_tcm/glove_word_vectors_2015_2021_cve_tSparse_tcm")


rownames(glove_vectors)=tSparse_colnames

#for coherence calucalation
tcm=readRDS("tcm_train")
colnames(tcm)=tSparse_colnames
rownames(tcm)=tSparse_colnames

col_sums=readRDS("col_sums_train")
l=10 # No top terms
rows_train=96594


#umap
library(uwot)
umap_tcm_ii=umap(X = glove_vectors,verbose = TRUE,n_neighbors =5,metric = "cosine",n_components = 2,local_connectivity =1)# ,n_epochs = 10000 , 5 or 10 neighbors 



rownames(umap_tcm_ii)=tSparse_colnames


####Select the best Fuzzy k-means model
library(fclust)
library(factoextra)

for(i in 2:30){
  #f_clust=FKM.pf(X = umap_tcm_ii,k = i) # or FKM.gb etc. , FKM and pf.noise and pf
  f_clust=FKM(X = umap_tcm_ii,k = i)
  
  #Find top terms of each cluster
  ldaOut.terms=matrix(ncol = f_clust$k,nrow=l)
  
  for(i in 1:ncol(ldaOut.terms)){
    ldaOut.terms[,i]=names(sort(f_clust$U[,i]*col_sums,decreasing = T))[1:l]
    #ldaOut.terms[,i]=names(sort(f_clust$U[,i],decreasing = T))[1:l]
    
    
  }
  
  library(text2vec)
  coherence_list=coherence(ldaOut.terms, tcm,n_doc_tcm =rows_train,metrics ="mean_npmi")
  ch=mean(coherence_list)
  
  print(paste(i,ch))
  
  if(i ==2){
    max_coh=ch
    f_clust_final=f_clust
  }else if(ch>max_coh){
    f_clust_final=f_clust
    max_coh=ch
    
  }
}

f_clust=f_clust_final

#Calculate the document-cluster matrix
tSparse_fclust=as.matrix(tSparse)%*%f_clust$U
row_sums_check=rowSums(tSparse)
row_sums_check[row_sums_check==0]=1
tSparse_fclust=tSparse_fclust/row_sums_check






####Fit LDA
library(ldatuning)
library(topicmodels)

filename="LDA/VEM_ldatuning_2_30"
row_s=rowSums(tSparse)
col_s=colSums(tSparse)
tSparse[which(row_s==0),which(col_s==max(col_s))]=1



result <- FindTopicsNumber(
  tSparse[split2$x,],
  topics = seq(from = 2, to = 30, by = 1),
  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "VEM",
  control = list(seed = 77,var=list(iter.max=1000,tol=0.0000005),em=list(iter.max=1000,tol=0.0000005)),
  #control = list(seed = 77),
  
  mc.cores = 4L,
  verbose = TRUE,
  return_models = TRUE,
  
  
)

ldaOut.terms=terms(model,10)# top terms for an LDA model


####Fit CTM
##CTM
library("topicmodels")
row_s=rowSums(tSparse)
col_s=colSums(tSparse)
tSparse[which(row_s==0),which(col_s==max(col_s))]=1

ctm_list=list()

for(i in 2:30){
  print(i)
  ctm_list[[i]] <- CTM(tSparse[split2$x==T,], k = i, control=list(seed=831))
  
}

ldaOut.terms=terms(model,10)# top terms for an CTM model


#####Calculate coherence
#for coherence
tcm=readRDS("tcm_train")
colnames(tcm)=tSparse_colnames
rownames(tcm)=tSparse_colnames

col_sums=readRDS("col_sums_train")
l=10
rows_train=96594




#########Fit Classification Models

#Replace tSparse_fclust with the posterior Document-topic memberships
new2_trainSparse=cbind(tSparse_fclust[split2$x==T,],categories_assignement[split2$x])
new2_testSparse=cbind(tSparse_fclust[split2$x==FALSE,],categories_assignement[split2$x==FALSE])

new2_trainSparse=as.data.frame(new2_trainSparse)
new2_testSparse=as.data.frame(new2_testSparse)


#Oversample
library(smotefamily)
Adasyn=ADAS(new2_trainSparse[,-ncol(new2_trainSparse)],new2_trainSparse[,ncol(new2_trainSparse)],K=5)

new2_trainSparse=Adasyn$data

colnames(new2_trainSparse)[ncol(new2_trainSparse)]="Exploit_output"
colnames(new2_testSparse)=colnames(new2_trainSparse)



##Machine learning with caret
library(MLmetrics)
source("Accurancy_2_Vectors_new.R")
library(caret)
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"

reg_models_names=c("rf","C5.0")

model_list=list()

###Hyper parameters tuning
hyperparams_grid=list()
hyperparams_grid[["rf"]]=expand.grid(mtry=10)

hyperparams_grid[["C5.0"]]=expand.grid(winnow=F,trials=50,model="tree")


###Train models
for(i in 1:length(reg_models_names)){
  print(paste(i,reg_models_names[i]))
  model_list[[reg_models_names[i]]]=train(Exploit_output~., 
                                          data=new2_trainSparse, method=reg_models_names[i],
                                          #tuneGrid=hyperparams_grid[[i]],
                                          tuneGrid=hyperparams_grid[[reg_models_names[i]]],
                                          metric=metric, trControl=control,)
}

###Predict new observations
pred_list=list()

for(i in 1:length(reg_models_names)){
  print(paste(i,reg_models_names[i]))
  pred_list[[reg_models_names[i]]]=predict(model_list[[reg_models_names[i]]],new2_testSparse)
  #pred_list[[reg_models_names[i]]]=predict(model_list[[reg_models_names[i]]],new2_testSparse,type="prob")
  
}


###Evaluate the models on the test set
eval_list=list()

for(i in 1:length(pred_list)){
  print(i)
  eval_list[[reg_models_names[i]]]=Accurancy_2_Vectors_new(predicts  = pred_list[[reg_models_names[i]]],
                                                           test =   new2_testSparse[,ncol(new2_testSparse)])
  
  
}

prob_list=list()
for(i in 1:length(reg_models_names)){
  print(paste(i,reg_models_names[i]))
  prob_list[[reg_models_names[i]]]=predict(model_list[[reg_models_names[i]]],new2_testSparse,type="prob")
  
}
AUC_new=list()
for(i in 1:length(reg_models_names)){
  AUC_new[[reg_models_names[i]]]=AUC(prob_list[[i]][[2]],y_true = new2_testSparse[,ncol(new2_testSparse)])
}

print(eval_list)
print(AUC_new)


library(pROC)
roc_score=roc(as.numeric(new2_testSparse$Exploit_output), as.numeric(prob_list[['rf']][[2]])) #AUC score for a random forest model

#http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf
plot(roc_score ,main ="ROC curve - AUC area",grid=1,type="l",legacy.axes=F,ylab="True Positive Rage (TPR)",xlab="1 - False Positive Rate (FPR)",print.thres=c(seq(0.1,0.9,0.1)),print.auc=T,auc.polygon=T,auc.polygon.col='#CCFFCC' )


